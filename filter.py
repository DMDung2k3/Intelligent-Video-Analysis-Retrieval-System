import os
import cv2
import torch
import numpy as np
import argparse
import pandas as pd
import shutil
from tqdm import tqdm
from PIL import Image
from transformers import AutoImageProcessor, AutoModel
from sklearn.metrics.pairwise import cosine_similarity

# ---------------- CONFIG ---------------- #
MODEL_NAME = "facebook/dino-vits16"
FRAME_SIZE = (224, 224)
TRANSITION_THRESHOLD = 0.75  # Giáº£m xuá»‘ng Ä‘á»ƒ Ã­t strict hÆ¡n trong viá»‡c phÃ¡t hiá»‡n chuyá»ƒn cáº£nh
MIN_SCENE_LENGTH = 2         # Giáº£m xuá»‘ng Ä‘á»ƒ cháº¥p nháº­n cáº£nh ngáº¯n hÆ¡n

# Quality filtering parameters (Ä‘iá»u chá»‰nh Ráº¤T má»m)
BLUR_PERCENTILE = 10.0       # Chá»‰ loáº¡i bá» 10% frame má» nháº¥t 
EDGE_PERCENTILE = 10.0       # Chá»‰ loáº¡i bá» 10% frame cÃ³ edge tháº¥p nháº¥t
ENABLE_ADAPTIVE_FILTERING = True  # Sá»­ dá»¥ng percentile thay vÃ¬ ngÆ°á»¡ng cá»‘ Ä‘á»‹nh

# Fixed thresholds (ráº¥t tháº¥p Ä‘á»ƒ giá»¯ nhiá»u frames)
BLUR_THRESHOLD = 10.0        # Giáº£m xuá»‘ng ráº¥t tháº¥p
EDGE_THRESHOLD = 5.0         # Giáº£m xuá»‘ng ráº¥t tháº¥p
ENABLE_BLUR_DETECTION = True
ENABLE_EDGE_DETECTION = True

# NEW: Similarity deduplication parameters
ENABLE_SIMILARITY_FILTERING = True  # Báº­t tÃ­nh nÄƒng lá»c frame tÆ°Æ¡ng tá»±
SIMILARITY_THRESHOLD = 0.95         # NgÆ°á»¡ng similarity Ä‘á»ƒ coi lÃ  "gáº§n giá»‘ng nhau"
MIN_FRAME_DISTANCE = 1              # Khoáº£ng cÃ¡ch tá»‘i thiá»ƒu giá»¯a cÃ¡c frame Ä‘Æ°á»£c giá»¯ láº¡i
SIMILARITY_WINDOW_SIZE = 5          # KÃ­ch thÆ°á»›c window Ä‘á»ƒ so sÃ¡nh similarity

# Default folders
DEFAULT_INPUT_KEYFRAMES_DIR = "keyframes"
DEFAULT_INPUT_MAP_DIR = "map"
DEFAULT_OUTPUT_KEYFRAMES_DIR = "keyframesv2.0"
DEFAULT_OUTPUT_MAP_DIR = "mapv2.0"
# ---------------------------------------- #

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Load DINO model
processor = AutoImageProcessor.from_pretrained(MODEL_NAME)
model = AutoModel.from_pretrained(MODEL_NAME).to(device)
model.eval()

def extract_embedding(image_path):
    """TrÃ­ch xuáº¥t embedding tá»« file áº£nh"""
    try:
        img = Image.open(image_path).convert('RGB').resize(FRAME_SIZE)
        inputs = processor(images=img, return_tensors="pt").to(device)
        with torch.no_grad():
            outputs = model(**inputs)
            embedding = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()
        return embedding
    except Exception as e:
        print(f"âŒ Lá»—i khi trÃ­ch xuáº¥t embedding tá»« {image_path}: {e}")
        return None

def calculate_blur_score(image_path):
    """TÃ­nh toÃ¡n Ä‘á»™ má» cá»§a áº£nh sá»­ dá»¥ng Laplacian variance"""
    try:
        image = cv2.imread(image_path)
        if image is None:
            return 0.0
        
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        
        return laplacian_var
    except Exception as e:
        return 0.0

def calculate_edge_density(image_path):
    """TÃ­nh toÃ¡n máº­t Ä‘á»™ edge Ä‘á»ƒ phÃ¡t hiá»‡n frame má»"""
    try:
        image = cv2.imread(image_path)
        if image is None:
            return 0.0
        
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # Sá»­ dá»¥ng threshold Ráº¤T tháº¥p cho Canny Ä‘á»ƒ detect nhiá»u edge hÆ¡n
        edges = cv2.Canny(gray, 20, 80)  # Giáº£m tá»« 30,100 xuá»‘ng 20,80
        edge_density = np.sum(edges > 0) / (edges.shape[0] * edges.shape[1]) * 100
        
        return edge_density
    except Exception as e:
        return 0.0

def calculate_frame_quality_scores(image_path):
    """TÃ­nh toÃ¡n cÃ¡c chá»‰ sá»‘ cháº¥t lÆ°á»£ng frame"""
    blur_score = calculate_blur_score(image_path)
    edge_density = calculate_edge_density(image_path)
    
    return {
        'blur_score': blur_score,
        'edge_density': edge_density
    }

def determine_adaptive_thresholds(all_quality_scores, config):
    """Tá»± Ä‘á»™ng xÃ¡c Ä‘á»‹nh ngÆ°á»¡ng dá»±a trÃªn phÃ¢n phá»‘i dá»¯ liá»‡u"""
    if not all_quality_scores:
        return None, None
    
    blur_scores = [q['blur_score'] for q in all_quality_scores]
    edge_scores = [q['edge_density'] for q in all_quality_scores]
    
    # TÃ­nh percentile thresholds
    blur_threshold = np.percentile(blur_scores, config['blur_percentile'])
    edge_threshold = np.percentile(edge_scores, config['edge_percentile'])
    
    return blur_threshold, edge_threshold

def is_frame_acceptable_adaptive(quality_scores, blur_threshold, edge_threshold, config):
    """Kiá»ƒm tra frame cÃ³ Ä‘áº¡t cháº¥t lÆ°á»£ng khÃ´ng (vá»›i adaptive thresholds)"""
    if config['enable_blur_detection'] and blur_threshold is not None:
        if quality_scores['blur_score'] < blur_threshold:
            return False, "blur"
    
    if config['enable_edge_detection'] and edge_threshold is not None:
        if quality_scores['edge_density'] < edge_threshold:
            return False, "low_edge"
    
    return True, "acceptable"

def is_frame_acceptable_fixed(quality_scores, config):
    """Kiá»ƒm tra frame cÃ³ Ä‘áº¡t cháº¥t lÆ°á»£ng khÃ´ng (vá»›i fixed thresholds)"""
    if config['enable_blur_detection']:
        if quality_scores['blur_score'] < config['blur_threshold']:
            return False, "blur"
    
    if config['enable_edge_detection']:
        if quality_scores['edge_density'] < config['edge_threshold']:
            return False, "low_edge"
    
    return True, "acceptable"

def calculate_similarities(embeddings):
    """TÃ­nh toÃ¡n cosine similarity giá»¯a cÃ¡c frame liÃªn tiáº¿p"""
    similarities = []
    for i in range(1, len(embeddings)):
        if embeddings[i-1] is not None and embeddings[i] is not None:
            sim = cosine_similarity([embeddings[i-1]], [embeddings[i]])[0][0]
            similarities.append(sim)
        else:
            similarities.append(1.0)
    return similarities

def detect_scene_transitions(similarities, threshold):
    """PhÃ¡t hiá»‡n cÃ¡c Ä‘iá»ƒm chuyá»ƒn cáº£nh dá»±a trÃªn similarity tháº¥p"""
    transition_points = []
    for i, sim in enumerate(similarities):
        if sim < threshold:
            transition_points.append(i + 1)
    return transition_points

def group_into_scenes(transition_points, total_frames, min_length):
    """NhÃ³m cÃ¡c frame thÃ nh cÃ¡c cáº£nh vÃ  loáº¡i bá» cáº£nh quÃ¡ ngáº¯n"""
    scenes = []
    start_idx = 0
    
    for transition_idx in transition_points:
        scene_length = transition_idx - start_idx
        if scene_length >= min_length:
            scenes.append((start_idx, transition_idx - 1))
        start_idx = transition_idx
    
    final_scene_length = total_frames - start_idx
    if final_scene_length >= min_length:
        scenes.append((start_idx, total_frames - 1))
    
    return scenes

def filter_similar_frames_in_scene(scene_embeddings, scene_indices, config):
    """
    Lá»c bá» cÃ¡c frame tÆ°Æ¡ng tá»± nhau trong má»™t scene
    
    Args:
        scene_embeddings: List embeddings cá»§a cÃ¡c frame trong scene
        scene_indices: List cÃ¡c index tÆ°Æ¡ng á»©ng vá»›i embeddings
        config: Dictionary chá»©a cÃ¡c tham sá»‘ cáº¥u hÃ¬nh
    
    Returns:
        List cÃ¡c indices Ä‘Æ°á»£c giá»¯ láº¡i sau khi lá»c
    """
    if not config['enable_similarity_filtering'] or len(scene_embeddings) <= 1:
        return scene_indices
    
    similarity_threshold = config['similarity_threshold']
    min_distance = config['min_frame_distance']
    
    kept_indices = [0]  # LuÃ´n giá»¯ frame Ä‘áº§u tiÃªn cá»§a scene
    last_kept_idx = 0
    
    for i in range(1, len(scene_embeddings)):
        current_embedding = scene_embeddings[i]
        
        # Kiá»ƒm tra khoáº£ng cÃ¡ch tá»‘i thiá»ƒu
        if i - last_kept_idx < min_distance:
            continue
            
        # So sÃ¡nh vá»›i frame Ä‘Æ°á»£c giá»¯ gáº§n nháº¥t
        last_kept_embedding = scene_embeddings[last_kept_idx]
        similarity = cosine_similarity([current_embedding], [last_kept_embedding])[0][0]
        
        # Náº¿u similarity tháº¥p hÆ¡n threshold, giá»¯ frame nÃ y
        if similarity < similarity_threshold:
            kept_indices.append(i)
            last_kept_idx = i
    
    # LuÃ´n giá»¯ frame cuá»‘i cÃ¹ng cá»§a scene náº¿u chÆ°a Ä‘Æ°á»£c giá»¯
    if kept_indices[-1] != len(scene_embeddings) - 1:
        kept_indices.append(len(scene_embeddings) - 1)
    
    # Chuyá»ƒn Ä‘á»•i local indices thÃ nh global indices
    global_kept_indices = [scene_indices[i] for i in kept_indices]
    
    return global_kept_indices

def filter_similar_frames_advanced(scene_embeddings, scene_indices, config):
    """
    Lá»c frame tÆ°Æ¡ng tá»± vá»›i thuáº­t toÃ¡n sliding window advanced
    """
    if not config['enable_similarity_filtering'] or len(scene_embeddings) <= 1:
        return scene_indices
    
    similarity_threshold = config['similarity_threshold']
    window_size = min(config['similarity_window_size'], len(scene_embeddings))
    
    kept_indices = [0]  # LuÃ´n giá»¯ frame Ä‘áº§u tiÃªn
    
    for i in range(1, len(scene_embeddings)):
        current_embedding = scene_embeddings[i]
        should_keep = True
        
        # So sÃ¡nh vá»›i cÃ¡c frame trong window
        window_start = max(0, i - window_size)
        for j in range(window_start, i):
            if j in kept_indices:  # Chá»‰ so sÃ¡nh vá»›i frames Ä‘Ã£ Ä‘Æ°á»£c giá»¯ láº¡i
                local_j = kept_indices.index(j) if j in kept_indices else -1
                if local_j >= 0:
                    past_embedding = scene_embeddings[j]
                    similarity = cosine_similarity([current_embedding], [past_embedding])[0][0]
                    
                    if similarity >= similarity_threshold:
                        should_keep = False
                        break
        
        if should_keep:
            kept_indices.append(i)
    
    # Chuyá»ƒn Ä‘á»•i local indices thÃ nh global indices
    global_kept_indices = [scene_indices[i] for i in kept_indices]
    
    return global_kept_indices

def apply_similarity_filtering_to_scenes(embeddings, valid_rows, scenes, config):
    """
    Ãp dá»¥ng lá»c similarity cho táº¥t cáº£ cÃ¡c scenes
    
    Returns:
        Tuple (filtered_embeddings, filtered_rows, similarity_stats)
    """
    if not config['enable_similarity_filtering']:
        # Táº¡o indices cho táº¥t cáº£ frames trong scenes
        all_scene_indices = []
        for scene_start, scene_end in scenes:
            for i in range(scene_start, scene_end + 1):
                all_scene_indices.append(i)
        
        filtered_embeddings = [embeddings[i] for i in all_scene_indices]
        filtered_rows = [valid_rows[i] for i in all_scene_indices]
        return filtered_embeddings, filtered_rows, {'original': len(all_scene_indices), 'filtered': len(all_scene_indices), 'removed': 0}
    
    print("ğŸ”„ Äang lá»c cÃ¡c frame tÆ°Æ¡ng tá»± nhau trong tá»«ng scene...")
    
    all_kept_indices = []
    similarity_stats = {'original': 0, 'filtered': 0, 'removed': 0}
    
    for scene_idx, (scene_start, scene_end) in enumerate(scenes):
        scene_length = scene_end - scene_start + 1
        scene_embeddings = embeddings[scene_start:scene_end + 1]
        scene_indices = list(range(scene_start, scene_end + 1))
        
        similarity_stats['original'] += scene_length
        
        # Ãp dá»¥ng lá»c similarity cho scene nÃ y
        if config.get('use_advanced_similarity_filtering', False):
            kept_indices = filter_similar_frames_advanced(scene_embeddings, scene_indices, config)
        else:
            kept_indices = filter_similar_frames_in_scene(scene_embeddings, scene_indices, config)
        
        all_kept_indices.extend(kept_indices)
        similarity_stats['filtered'] += len(kept_indices)
        
        print(f"   ğŸ¬ Scene {scene_idx + 1}: {scene_length} â†’ {len(kept_indices)} frames "
              f"(loáº¡i bá» {scene_length - len(kept_indices)})")
    
    similarity_stats['removed'] = similarity_stats['original'] - similarity_stats['filtered']
    
    # Táº¡o danh sÃ¡ch káº¿t quáº£
    filtered_embeddings = [embeddings[i] for i in all_kept_indices]
    filtered_rows = [valid_rows[i] for i in all_kept_indices]
    
    print(f"ğŸ“Š Káº¿t quáº£ lá»c similarity:")
    print(f"   ğŸ“¥ Frames Ä‘áº§u vÃ o: {similarity_stats['original']}")
    print(f"   ğŸ“¤ Frames giá»¯ láº¡i: {similarity_stats['filtered']}")
    print(f"   ğŸ—‘ï¸ Frames loáº¡i bá»: {similarity_stats['removed']}")
    print(f"   ğŸ“Š Tá»· lá»‡ loáº¡i bá»: {(similarity_stats['removed'] / similarity_stats['original'] * 100):.1f}%")
    
    return filtered_embeddings, filtered_rows, similarity_stats

def filter_transition_frames_for_video(video_name, config):
    """Lá»c cÃ¡c frame chuyá»ƒn cáº£nh vÃ  frame má» cho má»™t video cá»¥ thá»ƒ"""
    print(f"\nğŸ¬ Äang xá»­ lÃ½ video: {video_name}")
    
    # ÄÆ°á»ng dáº«n cÃ¡c file vÃ  folder
    csv_path = os.path.join(config['input_map_dir'], f"{video_name}.csv")
    input_frames_dir = os.path.join(config['input_keyframes_dir'], video_name)
    output_frames_dir = os.path.join(config['output_keyframes_dir'], video_name)
    output_csv_path = os.path.join(config['output_map_dir'], f"{video_name}.csv")
    
    # Kiá»ƒm tra file CSV tá»“n táº¡i
    if not os.path.exists(csv_path):
        print(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y file CSV: {csv_path}")
        return None
    
    if not os.path.exists(input_frames_dir):
        print(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y folder frames: {input_frames_dir}")
        return None
    
    # Äá»c CSV mapping
    try:
        df = pd.read_csv(csv_path)
        print(f"ğŸ“„ Äá»c Ä‘Æ°á»£c {len(df)} frames tá»« CSV")
    except Exception as e:
        print(f"âŒ Lá»—i khi Ä‘á»c CSV {csv_path}: {e}")
        return None
    
    os.makedirs(output_frames_dir, exist_ok=True)
    
    # Phase 1: TÃ­nh toÃ¡n cháº¥t lÆ°á»£ng cho Táº¤T Cáº¢ frames trÆ°á»›c
    print("ğŸ” Äang phÃ¢n tÃ­ch cháº¥t lÆ°á»£ng táº¥t cáº£ frames...")
    all_quality_scores = []
    all_valid_paths = []
    
    for idx, row in tqdm(df.iterrows(), total=len(df), desc="Analyzing all frames"):
        frame_filename = f"{row['frame_idx']}.jpg"
        frame_path = os.path.join(input_frames_dir, frame_filename)
        
        if os.path.exists(frame_path):
            quality = calculate_frame_quality_scores(frame_path)
            all_quality_scores.append(quality)
            all_valid_paths.append((frame_path, row))
        else:
            print(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y frame: {frame_path}")
    
    if not all_quality_scores:
        print("âŒ KhÃ´ng cÃ³ frame nÃ o Ä‘á»ƒ phÃ¢n tÃ­ch")
        return None
    
    # Hiá»ƒn thá»‹ thá»‘ng kÃª cháº¥t lÆ°á»£ng
    blur_scores = [q['blur_score'] for q in all_quality_scores]
    edge_scores = [q['edge_density'] for q in all_quality_scores]
    
    print(f"ğŸ“Š Thá»‘ng kÃª cháº¥t lÆ°á»£ng:")
    print(f"   ğŸŒ«ï¸ Blur score: min={min(blur_scores):.1f}, max={max(blur_scores):.1f}, "
          f"median={np.median(blur_scores):.1f}")
    print(f"   ğŸ“ Edge density: min={min(edge_scores):.1f}%, max={max(edge_scores):.1f}%, "
          f"median={np.median(edge_scores):.1f}%")
    
    # Phase 2: XÃ¡c Ä‘á»‹nh ngÆ°á»¡ng (adaptive hoáº·c fixed)
    if config['enable_adaptive_filtering']:
        blur_threshold, edge_threshold = determine_adaptive_thresholds(all_quality_scores, config)
        print(f"ğŸ“ NgÆ°á»¡ng adaptive:")
        if blur_threshold is not None:
            print(f"   ğŸŒ«ï¸ Blur threshold (percentile {config['blur_percentile']}): {blur_threshold:.1f}")
        if edge_threshold is not None:
            print(f"   ğŸ“ Edge threshold (percentile {config['edge_percentile']}): {edge_threshold:.1f}%")
    else:
        blur_threshold = config['blur_threshold']
        edge_threshold = config['edge_threshold']
        print(f"ğŸ“ NgÆ°á»¡ng cá»‘ Ä‘á»‹nh:")
        print(f"   ğŸŒ«ï¸ Blur threshold: {blur_threshold}")
        print(f"   ğŸ“ Edge threshold: {edge_threshold}%")
    
    # Phase 3: Lá»c theo cháº¥t lÆ°á»£ng
    print("ğŸ” Äang lá»c theo cháº¥t lÆ°á»£ng...")
    embeddings = []
    valid_rows = []
    quality_filter_stats = {'blur': 0, 'low_edge': 0, 'acceptable': 0, 'embedding_error': 0}
    
    for i, (frame_path, row) in enumerate(tqdm(all_valid_paths, desc="Quality filtering")):
        quality = all_quality_scores[i]
        
        if config['enable_adaptive_filtering']:
            is_acceptable, reason = is_frame_acceptable_adaptive(quality, blur_threshold, edge_threshold, config)
        else:
            is_acceptable, reason = is_frame_acceptable_fixed(quality, config)
        
        if is_acceptable:
            emb = extract_embedding(frame_path)
            if emb is not None:
                embeddings.append(emb)
                valid_rows.append(row)
                quality_filter_stats['acceptable'] += 1
            else:
                quality_filter_stats['embedding_error'] += 1
        else:
            quality_filter_stats[reason] += 1
    
    print(f"ğŸ“Š Káº¿t quáº£ lá»c cháº¥t lÆ°á»£ng:")
    print(f"   âœ… Cháº¥p nháº­n Ä‘Æ°á»£c: {quality_filter_stats['acceptable']}")
    print(f"   ğŸŒ«ï¸ Bá»‹ má»: {quality_filter_stats['blur']}")
    print(f"   ğŸ“‰ Edge tháº¥p: {quality_filter_stats['low_edge']}")
    print(f"   âŒ Lá»—i embedding: {quality_filter_stats['embedding_error']}")
    
    # Cáº£nh bÃ¡o náº¿u loáº¡i bá» quÃ¡ nhiá»u
    total_processed = len(all_valid_paths)
    kept_percentage = (quality_filter_stats['acceptable'] / total_processed) * 100 if total_processed > 0 else 0
    if kept_percentage < 30:
        print(f"âš ï¸ Cáº¢NH BÃO: Chá»‰ giá»¯ láº¡i {kept_percentage:.1f}% frames! HÃ£y thá»­:")
        print(f"   ğŸŒ¸ --ultra_gentle (chá»‰ lá»c chuyá»ƒn cáº£nh)")
        print(f"   ğŸŒ¿ --gentle (chá»‰ loáº¡i bá» 5% frame tá»‡ nháº¥t)")
        print(f"   ğŸ“ --blur_percentile 5.0 --edge_percentile 5.0")
    
    if len(embeddings) < config['min_scene_length']:
        print(f"âš ï¸ KhÃ´ng Ä‘á»§ frames cháº¥t lÆ°á»£ng tá»‘t Ä‘á»ƒ xá»­ lÃ½ (cáº§n Ã­t nháº¥t {config['min_scene_length']} frames)")
        return None
    
    # Phase 4: PhÃ¡t hiá»‡n chuyá»ƒn cáº£nh
    print("ğŸ“Š Äang tÃ­nh toÃ¡n similarities...")
    similarities = calculate_similarities(embeddings)
    avg_similarity = np.mean(similarities)
    print(f"ğŸ“ˆ Similarity trung bÃ¬nh: {avg_similarity:.3f}")
    
    transition_points = detect_scene_transitions(similarities, config['transition_threshold'])
    print(f"ğŸ­ PhÃ¡t hiá»‡n {len(transition_points)} Ä‘iá»ƒm chuyá»ƒn cáº£nh")
    
    scenes = group_into_scenes(transition_points, len(embeddings), config['min_scene_length'])
    print(f"ğŸï¸ TÃ¬m tháº¥y {len(scenes)} cáº£nh há»£p lá»‡")
    
    if not scenes:
        print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y cáº£nh nÃ o há»£p lá»‡")
        return None
    
    # Phase 5: NEW - Lá»c cÃ¡c frame tÆ°Æ¡ng tá»± nhau trong tá»«ng scene
    filtered_embeddings, filtered_rows, similarity_stats = apply_similarity_filtering_to_scenes(
        embeddings, valid_rows, scenes, config
    )
    
    # Phase 6: Táº¡o DataFrame cuá»‘i cÃ¹ng
    final_df = pd.DataFrame(filtered_rows)
    final_df = final_df.reset_index(drop=True)
    final_df['n'] = range(len(final_df))
    
    # Phase 7: Copy frames
    print(f"ğŸ’¾ Äang copy {len(final_df)} frames cháº¥t lÆ°á»£ng cao...")
    copied_count = 0
    copy_errors = 0
    
    for _, row in tqdm(final_df.iterrows(), total=len(final_df), desc="Copying frames"):
        source_frame = f"{row['frame_idx']}.jpg"
        source_path = os.path.join(input_frames_dir, source_frame)
        dest_path = os.path.join(output_frames_dir, source_frame)
        
        try:
            if os.path.exists(source_path):
                shutil.copy2(source_path, dest_path)
                copied_count += 1
            else:
                copy_errors += 1
        except Exception as e:
            copy_errors += 1
    
    # Phase 8: LÆ°u CSV
    try:
        final_df.to_csv(output_csv_path, index=False)
        print(f"ğŸ“„ ÄÃ£ lÆ°u CSV má»›i: {output_csv_path}")
    except Exception as e:
        print(f"âŒ Lá»—i khi lÆ°u CSV: {e}")
        return None
    
    # Thá»‘ng kÃª káº¿t quáº£
    original_count = len(df)
    quality_passed = quality_filter_stats['acceptable']
    scene_filtered = similarity_stats['filtered']
    final_count = len(final_df)
    
    quality_removed = original_count - quality_passed
    similarity_removed = similarity_stats['removed']
    total_removed = original_count - final_count
    removal_percentage = (total_removed / original_count) * 100 if original_count > 0 else 0
    
    print(f"âœ… HoÃ n thÃ nh video {video_name}!")
    print(f"ğŸ“Š Frames gá»‘c: {original_count}")
    print(f"ğŸ“Š Loáº¡i bá» do cháº¥t lÆ°á»£ng kÃ©m: {quality_removed}")
    print(f"ğŸ“Š Loáº¡i bá» do similarity cao: {similarity_removed}")
    print(f"ğŸ“Š Frames cuá»‘i cÃ¹ng: {final_count}")
    print(f"ğŸ“Š Tá»•ng loáº¡i bá»: {total_removed} ({removal_percentage:.1f}%)")
    print(f"ğŸ“Š Frames Ä‘Ã£ copy: {copied_count}")
    if copy_errors > 0:
        print(f"âš ï¸ Lá»—i copy: {copy_errors}")
    
    return {
        'video_name': video_name,
        'original_frames': original_count,
        'quality_passed': quality_passed,
        'scene_filtered': scene_filtered,
        'filtered_frames': final_count,
        'quality_removed': quality_removed,
        'similarity_removed': similarity_removed,
        'total_removed': total_removed,
        'removal_percentage': removal_percentage,
        'scenes_count': len(scenes),
        'transitions_count': len(transition_points),
        'avg_similarity': avg_similarity,
        'copied_frames': copied_count,
        'copy_errors': copy_errors,
        'quality_stats': quality_filter_stats,
        'similarity_stats': similarity_stats
    }

def process_all_videos(config):
    """Xá»­ lÃ½ táº¥t cáº£ cÃ¡c video trong folder keyframes vÃ  map"""
    print("ğŸš€ Báº®T Äáº¦U Xá»¬ LÃ ADAPTIVE FRAME FILTERING")
    print("=" * 70)
    
    if not os.path.exists(config['input_keyframes_dir']):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y folder keyframes: {config['input_keyframes_dir']}")
        return
    
    if not os.path.exists(config['input_map_dir']):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y folder map: {config['input_map_dir']}")
        return
    
    os.makedirs(config['output_keyframes_dir'], exist_ok=True)
    os.makedirs(config['output_map_dir'], exist_ok=True)
    
    csv_files = [f for f in os.listdir(config['input_map_dir']) if f.endswith('.csv')]
    video_names = [os.path.splitext(f)[0] for f in csv_files]
    
    if not video_names:
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file CSV nÃ o trong folder: {config['input_map_dir']}")
        return
    
    print(f"ğŸ¯ TÃ¬m tháº¥y {len(video_names)} video Ä‘á»ƒ xá»­ lÃ½:")
    for i, name in enumerate(video_names, 1):
        print(f"   {i}. {name}")
    
    print(f"\nâš™ï¸ Cáº¥u hÃ¬nh:")
    print(f"   ğŸ“‚ Input keyframes: {config['input_keyframes_dir']}")
    print(f"   ğŸ“‚ Output keyframes: {config['output_keyframes_dir']}")
    print(f"   ğŸ­ Transition threshold: {config['transition_threshold']}")
    if config['enable_adaptive_filtering']:
        print(f"   ğŸ¤– Adaptive filtering: Báº­t")
        if config['enable_blur_detection']:
            print(f"      ğŸŒ«ï¸ Blur percentile: {config['blur_percentile']}%")
        if config['enable_edge_detection']:
            print(f"      ğŸ“ Edge percentile: {config['edge_percentile']}%")
    else:
        print(f"   ğŸ¯ Fixed thresholds:")
        if config['enable_blur_detection']:
            print(f"      ğŸŒ«ï¸ Blur threshold: {config['blur_threshold']}")
        if config['enable_edge_detection']:
            print(f"      ğŸ“ Edge threshold: {config['edge_threshold']}%")
    
    # NEW: Hiá»ƒn thá»‹ cáº¥u hÃ¬nh similarity filtering
    if config['enable_similarity_filtering']:
        print(f"   ğŸ”„ Similarity filtering: Báº­t")
        print(f"      ğŸ¯ Similarity threshold: {config['similarity_threshold']}")
        print(f"      ğŸ“ Min frame distance: {config['min_frame_distance']}")
        print(f"      ğŸªŸ Window size: {config['similarity_window_size']}")
    else:
        print(f"   ğŸ”„ Similarity filtering: Táº¯t")
    
    print(f"   ğŸ–¥ï¸ Device: {device}")
    print("=" * 70)
    
    results = []
    successful_videos = 0
    
    for i, video_name in enumerate(video_names, 1):
        print(f"\n[{i}/{len(video_names)}] ğŸ¬ Äang xá»­ lÃ½: {video_name}")
        print("-" * 60)
        
        try:
            result = filter_transition_frames_for_video(video_name, config)
            if result:
                results.append(result)
                successful_videos += 1
            else:
                print(f"âŒ KhÃ´ng thá»ƒ xá»­ lÃ½ video: {video_name}")
        except Exception as e:
            print(f"âŒ Lá»—i khi xá»­ lÃ½ video {video_name}: {str(e)}")
    
    # Tá»•ng káº¿t
    if results:
        print("\n" + "=" * 70)
        print("ğŸ“Š Tá»”NG Káº¾T Káº¾T QUáº¢")
        print("=" * 70)
        
        total_original = sum(r['original_frames'] for r in results)
        total_final = sum(r['filtered_frames'] for r in results)
        total_removed = sum(r['total_removed'] for r in results)
        total_similarity_removed = sum(r['similarity_removed'] for r in results)
        avg_removal_rate = np.mean([r['removal_percentage'] for r in results])
        
        print(f"âœ… ÄÃ£ xá»­ lÃ½ thÃ nh cÃ´ng: {successful_videos}/{len(video_names)} videos")
        print(f"ğŸ–¼ï¸ Tá»•ng frames gá»‘c: {total_original:,}")
        print(f"âœ… Tá»•ng frames cuá»‘i cÃ¹ng: {total_final:,}")
        print(f"ğŸ—‘ï¸ Tá»•ng frames Ä‘Ã£ loáº¡i bá»: {total_removed:,}")
        print(f"   ğŸ”„ Loáº¡i bá» do similarity: {total_similarity_removed:,}")
        print(f"ğŸ“Š Tá»· lá»‡ loáº¡i bá» trung bÃ¬nh: {avg_removal_rate:.1f}%")
        
        print(f"\nğŸ‰ HOÃ€N THÃ€NH! Káº¿t quáº£ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i:")
        print(f"   ğŸ“‚ {config['output_keyframes_dir']}")
        print(f"   ğŸ“‚ {config['output_map_dir']}")

def create_config(args):
    """Táº¡o dictionary config tá»« arguments"""
    return {
        'input_keyframes_dir': args.input_keyframes,
        'input_map_dir': args.input_map,
        'output_keyframes_dir': args.output_keyframes,
        'output_map_dir': args.output_map,
        'transition_threshold': args.threshold,
        'min_scene_length': args.min_scene_length,
        'blur_threshold': args.blur_threshold,
        'enable_blur_detection': args.enable_blur_detection,
        'edge_threshold': args.edge_threshold,
        'enable_edge_detection': args.enable_edge_detection,
        'enable_adaptive_filtering': args.enable_adaptive_filtering,
        'blur_percentile': args.blur_percentile,
        'edge_percentile': args.edge_percentile,
        # NEW: Similarity filtering parameters
        'enable_similarity_filtering': args.enable_similarity_filtering,
        'similarity_threshold': args.similarity_threshold,
        'min_frame_distance': args.min_frame_distance,
        'similarity_window_size': args.similarity_window_size,
        'use_advanced_similarity_filtering': args.use_advanced_similarity_filtering
    }

def main():
    parser = argparse.ArgumentParser(
        description="Lá»c bá» frame chuyá»ƒn cáº£nh, frame má» vÃ  frame tÆ°Æ¡ng tá»± vá»›i adaptive thresholds"
    )
    parser.add_argument("--input_keyframes", type=str, default=DEFAULT_INPUT_KEYFRAMES_DIR)
    parser.add_argument("--input_map", type=str, default=DEFAULT_INPUT_MAP_DIR)
    parser.add_argument("--output_keyframes", type=str, default=DEFAULT_OUTPUT_KEYFRAMES_DIR)
    parser.add_argument("--output_map", type=str, default=DEFAULT_OUTPUT_MAP_DIR)
    parser.add_argument("--threshold", type=float, default=TRANSITION_THRESHOLD)
    parser.add_argument("--min_scene_length", type=int, default=MIN_SCENE_LENGTH)
    
    # Adaptive filtering
    parser.add_argument("--enable_adaptive_filtering", action="store_true", default=ENABLE_ADAPTIVE_FILTERING)
    parser.add_argument("--disable_adaptive_filtering", action="store_true", default=False)
    parser.add_argument("--blur_percentile", type=float, default=BLUR_PERCENTILE,
                        help="Loáº¡i bá» N% frame má» nháº¥t (máº·c Ä‘á»‹nh: 10% - ráº¥t má»m)")
    parser.add_argument("--edge_percentile", type=float, default=EDGE_PERCENTILE,
                        help="Loáº¡i bá» N% frame cÃ³ edge tháº¥p nháº¥t (máº·c Ä‘á»‹nh: 10% - ráº¥t má»m)")
    
    # Fixed thresholds
    parser.add_argument("--blur_threshold", type=float, default=BLUR_THRESHOLD)
    parser.add_argument("--edge_threshold", type=float, default=EDGE_THRESHOLD)
    parser.add_argument("--enable_blur_detection", action="store_true", default=ENABLE_BLUR_DETECTION)
    parser.add_argument("--disable_blur_detection", action="store_true", default=False)
    parser.add_argument("--enable_edge_detection", action="store_true", default=ENABLE_EDGE_DETECTION)
    parser.add_argument("--disable_edge_detection", action="store_true", default=False)
    
    # NEW: Similarity filtering parameters
    parser.add_argument("--enable_similarity_filtering", action="store_true", default=ENABLE_SIMILARITY_FILTERING,
                        help="Báº­t tÃ­nh nÄƒng lá»c frame tÆ°Æ¡ng tá»± nhau")
    parser.add_argument("--disable_similarity_filtering", action="store_true", default=False,
                        help="Táº¯t tÃ­nh nÄƒng lá»c frame tÆ°Æ¡ng tá»± nhau")
    parser.add_argument("--similarity_threshold", type=float, default=SIMILARITY_THRESHOLD,
                        help="NgÆ°á»¡ng similarity Ä‘á»ƒ coi lÃ  gáº§n giá»‘ng nhau (0.0-1.0, máº·c Ä‘á»‹nh: 0.95)")
    parser.add_argument("--min_frame_distance", type=int, default=MIN_FRAME_DISTANCE,
                        help="Khoáº£ng cÃ¡ch tá»‘i thiá»ƒu giá»¯a cÃ¡c frame Ä‘Æ°á»£c giá»¯ láº¡i")
    parser.add_argument("--similarity_window_size", type=int, default=SIMILARITY_WINDOW_SIZE,
                        help="KÃ­ch thÆ°á»›c window Ä‘á»ƒ so sÃ¡nh similarity")
    parser.add_argument("--use_advanced_similarity_filtering", action="store_true", default=False,
                        help="Sá»­ dá»¥ng thuáº­t toÃ¡n similarity filtering nÃ¢ng cao")
    
    # Gentle filtering options
    parser.add_argument("--gentle", action="store_true", default=False,
                        help="Cháº¿ Ä‘á»™ lá»c nháº¹: chá»‰ loáº¡i bá» 5% frame tá»‡ nháº¥t")
    parser.add_argument("--ultra_gentle", action="store_true", default=False,
                        help="Cháº¿ Ä‘á»™ lá»c cá»±c nháº¹: chá»‰ lá»c chuyá»ƒn cáº£nh, khÃ´ng lá»c cháº¥t lÆ°á»£ng")
    parser.add_argument("--similarity_only", action="store_true", default=False,
                        help="Chá»‰ lá»c frame tÆ°Æ¡ng tá»±, khÃ´ng lá»c cháº¥t lÆ°á»£ng vÃ  chuyá»ƒn cáº£nh")
    
    parser.add_argument("--video", type=str, default=None)
    
    args = parser.parse_args()
    
    # Xá»­ lÃ½ gentle modes
    if args.ultra_gentle:
        args.enable_blur_detection = False
        args.enable_edge_detection = False
        print("ğŸŒ¸ Cháº¿ Ä‘á»™ Ultra Gentle: Chá»‰ lá»c chuyá»ƒn cáº£nh, giá»¯ nguyÃªn táº¥t cáº£ frames cháº¥t lÆ°á»£ng")
    elif args.gentle:
        args.blur_percentile = 5.0
        args.edge_percentile = 5.0
        print("ğŸŒ¿ Cháº¿ Ä‘á»™ Gentle: Chá»‰ loáº¡i bá» 5% frame tá»‡ nháº¥t")
    elif args.similarity_only:
        args.enable_blur_detection = False
        args.enable_edge_detection = False
        args.threshold = 0.0  # KhÃ´ng phÃ¡t hiá»‡n chuyá»ƒn cáº£nh
        print("ğŸ”„ Cháº¿ Ä‘á»™ Similarity Only: Chá»‰ lá»c frame tÆ°Æ¡ng tá»±")
    
    # Xá»­ lÃ½ flags
    if args.disable_adaptive_filtering:
        args.enable_adaptive_filtering = False
    if args.disable_blur_detection:
        args.enable_blur_detection = False
    if args.disable_edge_detection:
        args.enable_edge_detection = False
    if args.disable_similarity_filtering:
        args.enable_similarity_filtering = False
    
    config = create_config(args)
    
    print("ğŸš€ ADAPTIVE TRANSITION & BLUR FRAME FILTER WITH SIMILARITY DEDUPLICATION")
    print("=" * 80)
    
    if args.video:
        os.makedirs(config['output_keyframes_dir'], exist_ok=True)
        os.makedirs(config['output_map_dir'], exist_ok=True)
        result = filter_transition_frames_for_video(args.video, config)
        if result:
            print(f"\nâœ… HoÃ n thÃ nh video '{args.video}'!")
    else:
        process_all_videos(config)

if __name__ == "__main__":
    main()